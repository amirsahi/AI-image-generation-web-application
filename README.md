# FastAPI AI ImageÂ Generation Service

A lightweight REST API that turns text prompts into images using
`diffusers`/`torch`. Everything is wrapped in a Docker container for easy
deployment anywhere that can run containers.

## âœ¨Â Features
* **/generate** â€“ returns a PNG file  
  `GET /generate?prompt=Two+cats+playing+chess`
* **/generate-memory** â€“ streams the PNG inâ€‘memory (no temp file)  
  `GET /generate-memory?prompt=Cityscape+at+dusk`
* Simple CRUDâ€‘style sample routes (`/`, `/items/{id}`, `/items/`)

## ğŸ³Â QuickÂ start

```bash
# 1. Build the image
docker build -t ai-image-generator .

# 2. Run the container
docker run --rm -p 8000:8000 ai-image-generator
```

Visit **http://localhost:8000/docs** for the interactive Swagger UI.

## ğŸš€Â Example calls

```bash
# Save an image to disk
curl -o output.png \
  "http://localhost:8000/generate?prompt=A+sunset+over+mountains"

# Stream an image
curl "http://localhost:8000/generate-memory?prompt=Futuristic+bike"
```

## ğŸ› Â Local development
```bash
# Install dev tools
python -m venv .venv && source .venv/bin/activate
pip install -r dev-requirements.txt
pip install fastapi uvicorn[standard] pillow diffusers torch transformers

# Autoâ€‘format, lint, and typeâ€‘check
black .               # formatting
ruff check .          # lint
mypy .                # type hints
```
Run locally:

```bash
uvicorn main:app --reload --port 8000
```

## ğŸ—ï¸Â Producing images

The heavy lifting happens inside `ml.obtain_image()`, which should accept:

```python
image = obtain_image(
    prompt,
    num_inference_steps=50,
    seed=None,
    guidance_scale=7.5,
)
```

Make sure your implementation returns a `PIL.Image` instance.

## ğŸ“‚Â Project structure
```
.
â”œâ”€â”€ main.py               # FastAPI routes
â”œâ”€â”€ ml/                   # your ML / diffusion code
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ dev-requirements.txt  # lint, formatter, typing
â””â”€â”€ Dockerfile
```

## âš–ï¸Â License
MIT â€“ do what you want, but no warranty is provided.  
Remember to respect model licenses (e.g., Stable Diffusion) and content
policies when deploying publicly.
